{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_4041_ML_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import optimizers, regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras.backend as KerasBackend"
      ],
      "metadata": {
        "id": "MlRIzwSYFg7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxJJFaXfE8M1"
      },
      "outputs": [],
      "source": [
        "train_ds = pd.read_csv('/content/drive/MyDrive/datasets/train.csv')\n",
        "test_ds = pd.read_csv('/content/drive/MyDrive/datasets/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_timedata(timedata, y):\n",
        "  timedata_dt = timedata['date'].map(lambda x: pd.to_datetime(x, format = '%Y-%m-%d', errors = 'ignore'))\n",
        "  X = pd.DataFrame({'year': timedata_dt.dt.year-2013, 'month': timedata_dt.dt.month, 'day': timedata_dt.dt.day, \n",
        "                    'weekday': timedata_dt.dt.weekday, 'store': timedata.store, 'item': timedata.item}, \n",
        "                   columns = ['year', 'month', 'day', 'weekday', 'store', 'item'])\n",
        "  X = np.array(X)\n",
        "  Y = np.array(timedata[y])\n",
        "\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "7YaStp-kF3v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = extract_timedata(train_ds, 'sales')\n",
        "X_test, id_test = extract_timedata(test_ds, 'id')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3QZ8GpAJW64",
        "outputId": "f7692360-e5b1-4cb3-d40d-2f7e924ac9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(913000, 6) (913000,)\n",
            "(45000, 6) (45000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find out number of categories in each for embedding\n",
        "X_stacked = np.vstack((X_train, X_test)) # stack vertically\n",
        "print(\"years:\", len(np.unique(X_stacked[:, 0])))\n",
        "print(\"months:\", len(np.unique(X_stacked[:, 1])))\n",
        "print(\"days:\", len(np.unique(X_stacked[:, 2])))\n",
        "print(\"weekdays:\", len(np.unique(X_stacked[:, 3])))\n",
        "print(\"stores:\", len(np.unique(X_stacked[:, 4])))\n",
        "print(\"items:\", len(np.unique(X_stacked[:, 5])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDb7lX1kKXxm",
        "outputId": "f2ed1a0c-f94b-4d08-d335-5dd0074879b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "years: 6\n",
            "months: 12\n",
            "days: 31\n",
            "weekdays: 7\n",
            "stores: 10\n",
            "items: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation set - take last portion for time series\n",
        "# we take last 6 months of 2017 here - around 10% \n",
        "# July 2017 onwards - 4 = 2017 (since minus 2013) and >6 = July onwards\n",
        "X_val = X_train[(X_train[:, 0]==4)&(X_train[:, 1]>6)]\n",
        "Y_val = Y_train[(X_train[:, 0]==4)&(X_train[:, 1]>6)]\n",
        "X_train_split = X_train[(X_train[:, 0]!=4)|(X_train[:, 1]<7)]\n",
        "Y_train_split = Y_train[(X_train[:, 0]!=4)|(X_train[:, 1]<7)]\n",
        "\n",
        "print(X_train_split.shape, Y_train_split.shape)\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD5q05IlMNpL",
        "outputId": "a4df9774-44d2-40b8-ac51-8dd80762493e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(821000, 6) (821000,)\n",
            "(92000, 6) (92000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_split, X_val, Y_train_split, Y_val = train_test_split(X_train, Y_train, test_size=(1-0.9), random_state=0, shuffle = True)\n",
        "print(X_train_split.shape, Y_train_split.shape)\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4RplMj4sDCB",
        "outputId": "3c53da5f-8217-4606-eae9-c9889ac5da9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(821700, 6) (821700,)\n",
            "(91300, 6) (91300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# test run with smaller sample size\n",
        "sample_size = 5000\n",
        "ind = np.random.randint(X_train_split.shape[0], size=sample_size)\n",
        "X_train_sample, Y_train_sample = X_train_split[ind,:], Y_train_split[ind]\n",
        "'''"
      ],
      "metadata": {
        "id": "nWy8YW6KRBXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NNmodel():\n",
        "  # year not embedded, rest embed\n",
        "  input_year = Input(shape=(1,), name=\"year\")\n",
        "  inputs_model = [input_year]\n",
        "  outputs_embedded = [input_year]\n",
        "  features = {'month': 12, 'day': 31, 'weekday': 7, 'stores': 10, 'items': 50}\n",
        "  for key in features.keys():\n",
        "    input = Input(shape=(1,))\n",
        "    embedded = Embedding(features[key]+1, features[key]//2 +1, name=key+'_embedding')(input)\n",
        "    embedded = Reshape(target_shape=(features[key]//2 +1,))(embedded)\n",
        "    inputs_model.append(input)\n",
        "    outputs_embedded.append(embedded)\n",
        "\n",
        "  output_model = Concatenate()(outputs_embedded)\n",
        "  output_model = Dense(500)(output_model)\n",
        "  output_model = Activation('relu')(output_model)\n",
        "  output_model = Dense(100)(output_model)\n",
        "  output_model = Activation('relu')(output_model)\n",
        "  output_model = Dense(10)(output_model)\n",
        "  output_model = Activation('relu')(output_model)\n",
        "  output_model = Dense(1)(output_model)\n",
        "          \n",
        "  # loss function\n",
        "  def smape(x, y):\n",
        "    x, y = float(x), float(y)\n",
        "    return 100.*KerasBackend.mean(2*KerasBackend.abs(x-y)/(KerasBackend.abs(x)+KerasBackend.abs(y)))\n",
        "\n",
        "  def split_features(X):\n",
        "      result = []\n",
        "      for i in range(6):\n",
        "          result.append(X[:,i])\n",
        "      \n",
        "      return result\n",
        "\n",
        "  model = KerasModel(inputs=inputs_model, outputs=output_model)\n",
        "  model.compile(optimizer='Adam', loss=smape)\n",
        "  model.fit(split_features(X_train_split), Y_train_split,\n",
        "                        validation_data=(split_features(X_val), Y_val),\n",
        "                        epochs=10, batch_size=128,\n",
        "                        #callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
        "            )\n",
        "\n",
        "\n",
        "  # Val prediction results - SMAPE\n",
        "  val_prediction = model.predict(split_features(X_val)).flatten()\n",
        "\n",
        "  prediction = model.predict(split_features(X_test)).flatten()*0.981\n",
        "  return prediction\n"
      ],
      "metadata": {
        "id": "x4IntDLHRvF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# take avg\n",
        "predictions = []\n",
        "for i in range(25):\n",
        "  print('Iteration No. ', i+1)\n",
        "  predictions.append(NNmodel())\n",
        "prediction = np.array(predictions).mean(axis=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikxsFlD6Iu5D",
        "outputId": "f32c38f3-31ff-46f8-828a-afda00904168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No.  1\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 46s 7ms/step - loss: 14.1905 - val_loss: 12.6492\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7628 - val_loss: 12.6153\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7220 - val_loss: 12.9321\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6990 - val_loss: 12.6341\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6794 - val_loss: 12.5703\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6645 - val_loss: 12.7600\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6602 - val_loss: 12.7639\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6463 - val_loss: 12.5349\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6400 - val_loss: 12.5752\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6336 - val_loss: 12.6384\n",
            "Iteration No.  2\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 13.9819 - val_loss: 12.7595\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7696 - val_loss: 12.6430\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 33s 5ms/step - loss: 12.7251 - val_loss: 12.6333\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7014 - val_loss: 12.6600\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6833 - val_loss: 12.5956\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6683 - val_loss: 12.6572\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6594 - val_loss: 12.5385\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6446 - val_loss: 12.5890\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6365 - val_loss: 12.5426\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6310 - val_loss: 12.6790\n",
            "Iteration No.  3\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.7342 - val_loss: 12.6804\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7585 - val_loss: 12.6099\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7242 - val_loss: 12.6550\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7055 - val_loss: 12.6327\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6914 - val_loss: 12.7934\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6841 - val_loss: 12.6312\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6653 - val_loss: 12.6046\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6641 - val_loss: 12.5884\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6587 - val_loss: 12.5765\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6465 - val_loss: 12.5623\n",
            "Iteration No.  4\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.1628 - val_loss: 12.6613\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7585 - val_loss: 12.6025\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7257 - val_loss: 12.5752\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6989 - val_loss: 12.6451\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6844 - val_loss: 12.6503\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6669 - val_loss: 12.6007\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6641 - val_loss: 12.6239\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6511 - val_loss: 12.6131\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6458 - val_loss: 12.6107\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6407 - val_loss: 12.5978\n",
            "Iteration No.  5\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 36s 5ms/step - loss: 14.0375 - val_loss: 12.7066\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7696 - val_loss: 12.8889\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7282 - val_loss: 12.6096\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7051 - val_loss: 12.6126\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6812 - val_loss: 12.5808\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6739 - val_loss: 12.5863\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6563 - val_loss: 12.5544\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6472 - val_loss: 12.5777\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6410 - val_loss: 12.5566\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6356 - val_loss: 12.5904\n",
            "Iteration No.  6\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 14.2157 - val_loss: 12.7947\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.7496 - val_loss: 12.6193\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7177 - val_loss: 12.7232\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6918 - val_loss: 12.6261\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6737 - val_loss: 12.5954\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6603 - val_loss: 12.5641\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6489 - val_loss: 12.5649\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6437 - val_loss: 12.6019\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6346 - val_loss: 12.5288\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6270 - val_loss: 12.6132\n",
            "Iteration No.  7\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.2069 - val_loss: 12.6624\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7575 - val_loss: 12.7414\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7157 - val_loss: 12.5851\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6948 - val_loss: 12.5878\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6813 - val_loss: 12.5837\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6702 - val_loss: 12.5898\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6597 - val_loss: 12.7185\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6554 - val_loss: 12.5548\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6459 - val_loss: 12.6473\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6356 - val_loss: 12.6338\n",
            "Iteration No.  8\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 39s 6ms/step - loss: 13.9674 - val_loss: 12.6988\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7678 - val_loss: 12.7327\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7289 - val_loss: 12.6114\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.7017 - val_loss: 12.6316\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6871 - val_loss: 12.5771\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6699 - val_loss: 12.5801\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6565 - val_loss: 12.5637\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6516 - val_loss: 12.5849\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6406 - val_loss: 12.5523\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6320 - val_loss: 12.5665\n",
            "Iteration No.  9\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 14.0743 - val_loss: 12.6655\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7636 - val_loss: 12.7595\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.7258 - val_loss: 12.5923\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7019 - val_loss: 12.6065\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6839 - val_loss: 12.6121\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6647 - val_loss: 12.7921\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6583 - val_loss: 12.6165\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6443 - val_loss: 12.6221\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6367 - val_loss: 12.5549\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6330 - val_loss: 12.8297\n",
            "Iteration No.  10\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 36s 5ms/step - loss: 14.0734 - val_loss: 12.7048\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7620 - val_loss: 12.7858\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7277 - val_loss: 12.6345\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7021 - val_loss: 12.6407\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6836 - val_loss: 12.5833\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6682 - val_loss: 12.6055\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6559 - val_loss: 12.5704\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6510 - val_loss: 12.5782\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6407 - val_loss: 12.6107\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6347 - val_loss: 12.6031\n",
            "Iteration No.  11\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 36s 5ms/step - loss: 14.0954 - val_loss: 12.7883\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7709 - val_loss: 12.9623\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7318 - val_loss: 12.6121\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7080 - val_loss: 12.7530\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6902 - val_loss: 12.6415\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6748 - val_loss: 12.5807\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 33s 5ms/step - loss: 12.6552 - val_loss: 12.5853\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6478 - val_loss: 12.6103\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6434 - val_loss: 12.5844\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6403 - val_loss: 12.6697\n",
            "Iteration No.  12\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 14.0866 - val_loss: 12.8952\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7632 - val_loss: 12.9761\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7273 - val_loss: 12.6195\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6995 - val_loss: 12.7206\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6871 - val_loss: 12.9196\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6731 - val_loss: 12.6767\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6611 - val_loss: 12.7197\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6527 - val_loss: 12.7697\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6398 - val_loss: 12.5416\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6340 - val_loss: 12.5345\n",
            "Iteration No.  13\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.1174 - val_loss: 12.7407\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7678 - val_loss: 12.9662\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7293 - val_loss: 12.7394\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7119 - val_loss: 12.6313\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6844 - val_loss: 12.6139\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6728 - val_loss: 12.6144\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6666 - val_loss: 12.5867\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6561 - val_loss: 12.5908\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6483 - val_loss: 12.8086\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6441 - val_loss: 12.5950\n",
            "Iteration No.  14\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 39s 6ms/step - loss: 14.0108 - val_loss: 12.6519\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7678 - val_loss: 12.6195\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 39s 6ms/step - loss: 12.7273 - val_loss: 12.6002\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7003 - val_loss: 12.6182\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6861 - val_loss: 12.6761\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6739 - val_loss: 12.8135\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6608 - val_loss: 12.5875\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6571 - val_loss: 12.5905\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6516 - val_loss: 12.6753\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6459 - val_loss: 12.5758\n",
            "Iteration No.  15\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 14.3986 - val_loss: 12.7619\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7494 - val_loss: 12.8473\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 33s 5ms/step - loss: 12.7214 - val_loss: 12.7944\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6990 - val_loss: 12.6925\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6850 - val_loss: 12.7695\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6719 - val_loss: 12.5961\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6619 - val_loss: 12.5688\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6510 - val_loss: 12.6473\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6475 - val_loss: 12.5551\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6426 - val_loss: 12.5692\n",
            "Iteration No.  16\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.0292 - val_loss: 12.7627\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7580 - val_loss: 12.6318\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7282 - val_loss: 12.6007\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7052 - val_loss: 12.6597\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6875 - val_loss: 12.8602\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6760 - val_loss: 12.6037\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6628 - val_loss: 12.5746\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6583 - val_loss: 12.5958\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6480 - val_loss: 12.6776\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6432 - val_loss: 12.5789\n",
            "Iteration No.  17\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.1584 - val_loss: 12.7793\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7588 - val_loss: 12.6440\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7247 - val_loss: 12.6939\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7025 - val_loss: 12.6389\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6802 - val_loss: 12.7705\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6734 - val_loss: 12.5980\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6564 - val_loss: 12.6342\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6468 - val_loss: 12.5617\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6369 - val_loss: 12.6000\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6289 - val_loss: 12.5639\n",
            "Iteration No.  18\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.1623 - val_loss: 12.7710\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7583 - val_loss: 12.6939\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7276 - val_loss: 12.6741\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6927 - val_loss: 12.6054\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6794 - val_loss: 12.6189\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6666 - val_loss: 12.7817\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6540 - val_loss: 12.5898\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6437 - val_loss: 12.5681\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6399 - val_loss: 12.6487\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6346 - val_loss: 12.5575\n",
            "Iteration No.  19\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 36s 5ms/step - loss: 14.0549 - val_loss: 12.6882\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7609 - val_loss: 12.6318\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.7333 - val_loss: 12.8395\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6991 - val_loss: 12.8057\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6797 - val_loss: 12.6754\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6666 - val_loss: 12.5835\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6580 - val_loss: 12.6109\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6494 - val_loss: 12.5486\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6394 - val_loss: 12.6132\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6323 - val_loss: 12.5709\n",
            "Iteration No.  20\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 14.0314 - val_loss: 12.7430\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7620 - val_loss: 12.6726\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7277 - val_loss: 12.5845\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6986 - val_loss: 12.6492\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6810 - val_loss: 12.5811\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6663 - val_loss: 12.5538\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6553 - val_loss: 12.6538\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6489 - val_loss: 12.5472\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6415 - val_loss: 12.5205\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6303 - val_loss: 12.6720\n",
            "Iteration No.  21\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 14.1651 - val_loss: 12.7543\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.7631 - val_loss: 12.6521\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7244 - val_loss: 12.6624\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7037 - val_loss: 12.5733\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6824 - val_loss: 12.6307\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6709 - val_loss: 12.7072\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6638 - val_loss: 12.6130\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6476 - val_loss: 12.5802\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6465 - val_loss: 12.5377\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6356 - val_loss: 12.5487\n",
            "Iteration No.  22\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 39s 6ms/step - loss: 14.0962 - val_loss: 12.7987\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7606 - val_loss: 12.6903\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7303 - val_loss: 12.6979\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6988 - val_loss: 12.6076\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6865 - val_loss: 12.5952\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6752 - val_loss: 12.6212\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6621 - val_loss: 12.5685\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6553 - val_loss: 12.7021\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6460 - val_loss: 12.6209\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6386 - val_loss: 12.9866\n",
            "Iteration No.  23\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 14.1723 - val_loss: 12.6990\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7619 - val_loss: 12.6524\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7248 - val_loss: 12.6307\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.7030 - val_loss: 12.6369\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 35s 6ms/step - loss: 12.6906 - val_loss: 12.5575\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6736 - val_loss: 12.6741\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6600 - val_loss: 12.6695\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6516 - val_loss: 12.5728\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6473 - val_loss: 12.6804\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 54s 8ms/step - loss: 12.6355 - val_loss: 12.6346\n",
            "Iteration No.  24\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 45s 7ms/step - loss: 14.1622 - val_loss: 12.6255\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 40s 6ms/step - loss: 12.7664 - val_loss: 12.6150\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 41s 6ms/step - loss: 12.7261 - val_loss: 12.6040\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 40s 6ms/step - loss: 12.6976 - val_loss: 12.5951\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 39s 6ms/step - loss: 12.6828 - val_loss: 12.5637\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 39s 6ms/step - loss: 12.6739 - val_loss: 12.6128\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6677 - val_loss: 12.5860\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6588 - val_loss: 12.6217\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6556 - val_loss: 12.7724\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6413 - val_loss: 12.5616\n",
            "Iteration No.  25\n",
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 40s 6ms/step - loss: 14.0953 - val_loss: 12.7035\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.7753 - val_loss: 12.5923\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.7257 - val_loss: 12.6214\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.7100 - val_loss: 12.6059\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6817 - val_loss: 12.5882\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6659 - val_loss: 12.5686\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 38s 6ms/step - loss: 12.6590 - val_loss: 12.6472\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 36s 6ms/step - loss: 12.6462 - val_loss: 12.5918\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6379 - val_loss: 12.5930\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 37s 6ms/step - loss: 12.6329 - val_loss: 12.8311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction = NNmodel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tr2emOkslUE",
        "outputId": "42f07a66-3652-4276-f977-2e34b8b8fc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 14.1052 - val_loss: 12.7855\n",
            "Epoch 2/10\n",
            "6420/6420 [==============================] - 33s 5ms/step - loss: 12.7624 - val_loss: 12.7544\n",
            "Epoch 3/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.7276 - val_loss: 12.6411\n",
            "Epoch 4/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.7004 - val_loss: 12.6084\n",
            "Epoch 5/10\n",
            "6420/6420 [==============================] - 33s 5ms/step - loss: 12.6875 - val_loss: 12.6452\n",
            "Epoch 6/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6707 - val_loss: 12.6059\n",
            "Epoch 7/10\n",
            "6420/6420 [==============================] - 34s 5ms/step - loss: 12.6616 - val_loss: 12.5961\n",
            "Epoch 8/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6562 - val_loss: 12.6536\n",
            "Epoch 9/10\n",
            "6420/6420 [==============================] - 33s 5ms/step - loss: 12.6477 - val_loss: 12.5599\n",
            "Epoch 10/10\n",
            "6420/6420 [==============================] - 35s 5ms/step - loss: 12.6456 - val_loss: 12.6722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({'id': id_test, 'sales': prediction*1.006})\n",
        "results['sales'] = np.round(results['sales']).astype(int)\n",
        "results.head()"
      ],
      "metadata": {
        "id": "9XYppL25hA3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.to_csv('ML_results.csv', index=False)"
      ],
      "metadata": {
        "id": "tcgoJ36ziPKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}